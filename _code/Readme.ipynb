{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Service Sentiment Prediction\n",
    "\n",
    "\n",
    "\n",
    "## Summary \n",
    "\n",
    "This project is about building a model \n",
    "\n",
    "To give you a brief summary about the project, it is about building a model that can detect sentiment, so that I can apply this model to tweets from different cities, and compare/analyse how happy the tweets are from different cities.\n",
    "\n",
    "Small teams with limited or no customer service staff,  receiving customer service tweets directed towards them regularly. Repeated delay or bad customer service can result in a decrease in brand value over time. Can we help reduce tweet response time by creating a model that correctly classifies sentiment of each tweet? If so, the model can then be used for intelligent email routing, routing each tweet to the appropriate contact or department based on sentiment polarity and priority, using automation to limit the time it takes for the message to be received. For this reason, I believe this is an impactful business problem that warrants solving. \n",
    "\n",
    "## Quantifying business value \n",
    "\n",
    "Metrics should be\n",
    "- Easily measurable \n",
    "- Directly correlated to busienss performance \n",
    "- Predictive of future business outcomes\n",
    "- Isolated to factors controlled by the group it's measuring \n",
    "- Comparable to competitor's metrics \n",
    "    Outcome \n",
    "        - Customer experience?\n",
    "        - Revenue gain?\n",
    "        - Customer engagement?\n",
    "        - Business process automation?\n",
    "        - Better & faster decision making?\n",
    "    Output\n",
    "        - Model accuracy?\n",
    "        - Execution time\n",
    "        - Recall \n",
    "        - Precision\n",
    "\n",
    "* Classified CS tweets by sentiment\n",
    "* Improved response time by x days\n",
    "* Improve CS satisfaction \n",
    "\n",
    "## Addressing Unwanted Bias \n",
    "    Awareness \n",
    "        - Sentiment classification \n",
    "\n",
    "## Large volume of associated data?\n",
    "\n",
    "## The Data \n",
    "\n",
    "A tweet contains a lot of opinions about the data which are\n",
    "expressed in different ways by different users .The twitter\n",
    "dataset used in this survey work is already labeled into two\n",
    "classes viz. negative and positive polarity and thus the\n",
    "sentiment analysis of the data becomes easy to observe the\n",
    "effect of various features\n",
    "\n",
    "- How much data do you have? \n",
    "- Does the dataset match the problem? \n",
    "- Is the dataset complete?\n",
    "- Is the data annotated correctly for ML?\n",
    "\n",
    "## Further identifying the AI value \n",
    "\n",
    "## Project statement\n",
    "\n",
    "## Narrowing the business problem: \n",
    "\n",
    "## EDA \n",
    "\n",
    "## Models to use, why \n",
    "## Model evaluation \n",
    "\n",
    "--\n",
    "### Preprocessing of the dataset\n",
    "The raw data having polarity is highly susceptible to inconsistency and redundancy.\n",
    "Preprocessing of tweet include following points,\n",
    "     Remove all URLs (e.g. www.xyz.com), hash tags (e.g.\n",
    "    #topic), targets (@username)\n",
    "     Correct the spellings; sequence of repeated characters is to\n",
    "    be handled\n",
    "     Replace all the emoticons with their sentiment.\n",
    "     Remove all punctuations ,symbols, numbers\n",
    "     Remove Stop Words\n",
    "     Expand Acronyms(we can use a acronym dictionary)\n",
    "     Remove Non-English Tweets\n",
    "\n",
    "### Feature Extraction\n",
    "\n",
    "The preprocessed dataset has many distinctive properties. \n",
    "In the feature extraction method, we extract the aspects from the processed dataset. \n",
    "Later this aspect are used to compute the positive and negative polarity in a sentence which is useful for determining the opinion of the individuals using models like unigram, bigram [18]. Machine learning techniques require representing the key features of text or documents for processing. These key features are c o n s i d e r e d as feature vectors which are used for the classification task..Some examples features that havebeen reported in literature are:\n",
    "\n",
    "1. Words And Their Frequencies:\n",
    "Unigrams, bigrams and n-gram models with their frequency\n",
    "counts are considered as features. There has been more\n",
    "research on using word presence rather than frequencies to\n",
    "better describe this feature. Panget al. [23] showed better\n",
    "results by using presence instead of frequencies.\n",
    "2. Parts Of Speech Tags\n",
    "Parts of speech like adjectives, adverbs and somegroups of\n",
    "verbs and nouns are good indicators of subjectivity and\n",
    "sentiment. We can generate syntactic dependency patterns by\n",
    "parsing or dependency trees.\n",
    "3. Opinion Words And Phrases\n",
    "Apart from specific words, some phrases and idioms which\n",
    "convey sentiments can be used as features.\n",
    "e.g. cost someone an arm and leg.\n",
    "4. Position Of Terms\n",
    "The position of a term with in a text can affect on how much\n",
    "the term makes difference in overall sentiment of the text.\n",
    "5. Negation\n",
    "Negation is an important but difficult feature to interpret. The\n",
    "presence of a negation usually changes the polarity of the\n",
    "opinion..\n",
    "e.g., I am not happy.\n",
    "6. Syntax\n",
    "Syntactic patterns like collocations are used as features to\n",
    "learn subjectivity patterns by many of the researchers.\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
